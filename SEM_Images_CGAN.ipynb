{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogaxvRis0eFV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMFoJjuA-sgS",
        "outputId": "a2e0e353-2d61-481f-a1b2-a9b6b2134d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htiaNYM3__TW"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/drive/MyDrive/Dataset_SEM_Images/Denoised_Images'\n",
        "output_path = '/content/drive/MyDrive/Dataset_SEM_Images/Output_Images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Eh-vocUALKe"
      },
      "outputs": [],
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "device_use = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joRlPfX4CzYe"
      },
      "outputs": [],
      "source": [
        "class SEMImagesDataset(Dataset):\n",
        "  def __init__(self,ordered_path,unordered_path,transforms=None):\n",
        "\n",
        "    self.file_paths = []\n",
        "    self.labels = []\n",
        "    self.transforms = transforms\n",
        "\n",
        "    for path in os.listdir(ordered_path):\n",
        "      self.file_paths.append(os.path.join(ordered_path,path))\n",
        "      self.labels.append(1)\n",
        "\n",
        "    for path in os.listdir(unordered_path):\n",
        "      self.file_paths.append(os.path.join(unordered_path,path))\n",
        "      self.labels.append(0)\n",
        "\n",
        "    # self.train_file_paths = train_data['file_path'].values\n",
        "    # self.train_labels = train_data['label'].values\n",
        "\n",
        "    # self.test_file_paths = test_data['file_path'].values\n",
        "    # self.test_labels = test_data['label'].values\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_paths)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    image_path = self.file_paths[idx]\n",
        "    label = self.labels[idx]\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    if self.transforms:\n",
        "      image = self.transforms(image)\n",
        "\n",
        "    return image,label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzwf3FTeNZe9"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize((256,256)),\n",
        "                                transforms.Normalize([0.5],[0.5])])\n",
        "\n",
        "ordered_path = os.path.join(input_path,'Ordered')\n",
        "unordered_path = os.path.join(input_path,'Unordered')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTLAPA7HR14g"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "latent_dims = (32,32)\n",
        "label_dims = 2\n",
        "\n",
        "dataset = SEMImagesDataset(ordered_path,unordered_path,transform)\n",
        "\n",
        "total_dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-bklqcGY3RW"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator,self).__init__()\n",
        "    self.label_embedding = nn.Embedding(label_dims,label_dims)\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Conv2d(512,512,kernel_size=3,padding='same'),\n",
        "        nn.Conv2d(512,512,kernel_size=3,padding='same'),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(512,512,kernel_size=2,stride=2),\n",
        "        nn.Conv2d(512,256,kernel_size=3,padding='same'),\n",
        "        nn.Conv2d(256,256,kernel_size=3,padding='same'),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(256,256,kernel_size=2,stride=2),\n",
        "        nn.Conv2d(256,128,kernel_size=3,padding='same'),\n",
        "        nn.Conv2d(128,128,kernel_size=3,padding='same'),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(128,128,kernel_size=2,stride=2),\n",
        "        nn.Conv2d(128,64,kernel_size=3,padding='same'),\n",
        "        nn.Conv2d(64,64, kernel_size=3,padding='same'),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(64,64,kernel_size=2,stride=2),\n",
        "        nn.Conv2d(64,32,kernel_size=3,padding='same'),\n",
        "        nn.Conv2d(32,32,kernel_size=3,padding='same'),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(32,32,kernel_size=2,stride=2),\n",
        "        nn.Conv2d(32,16,kernel_size=3, padding='same'),\n",
        "        nn.Conv2d(16,16, kernel_size=3, padding='same'),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(16,1,kernel_size=3, padding='same'),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,noise, labels):\n",
        "    label_embed = labels.view(-1,)\n",
        "\n",
        "    label_embed = self.label_embedding(labels)\n",
        "    label_embed = label_embed.view(labels.size(0),label_dims,1,1)\n",
        "\n",
        "    label_embed = label_embed.expand(labels.size(0), label_dims, noise.size(2), noise.size(3))\n",
        "\n",
        "    g_in = torch.cat((noise, label_embed), dim=1)\n",
        "\n",
        "    return self.layers(g_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCKrtEm6WT1o",
        "outputId": "589a8d58-7620-4f61-fb4f-b63b803cb25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "# label_dims = 2\n",
        "\n",
        "# generator = Generator()\n",
        "\n",
        "# if cuda:\n",
        "#   generator = generator.cuda()\n",
        "\n",
        "# noise = torch.randn((32,510,8,8), device='cuda')\n",
        "# input_label = torch.randint(0,1,(32,1), device='cuda')\n",
        "\n",
        "# print(input_label.shape)\n",
        "\n",
        "# output = generator(noise,input_label)\n",
        "\n",
        "# print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC-oGWgHZTiU"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()\n",
        "\n",
        "    self.label_embedding = nn.Embedding(label_dims,label_dims)\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Conv2d(3,64,kernel_size=4,stride=2), # (Grayscale, one-hot encoding)\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(64,128,kernel_size=4,stride=2),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(128,256,kernel_size=4,stride=2),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(256,512,kernel_size=4,stride=2),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(512,1024, kernel_size=4,stride=2),\n",
        "        nn.Flatten(1),\n",
        "        nn.Linear(36864, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,img, labels):\n",
        "    label_embed = labels.view(-1,)\n",
        "\n",
        "    label_embed = self.label_embedding(labels)\n",
        "    label_embed = label_embed.view(labels.size(0),label_dims,1,1)\n",
        "\n",
        "    label_embed = label_embed.expand(labels.size(0), label_dims, img.size(2), img.size(3))\n",
        "\n",
        "    d_in = torch.cat((img, label_embed), dim=1)\n",
        "\n",
        "    return self.layers(d_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZbRb0k0CKud6",
        "outputId": "29f500ad-fbb5-4e8d-880f-5db53bd3aafa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1])\n",
            "torch.Size([32, 1])\n",
            "tensor([[0.4943],\n",
            "        [0.4952],\n",
            "        [0.4971],\n",
            "        [0.4994],\n",
            "        [0.4992],\n",
            "        [0.4848],\n",
            "        [0.4893],\n",
            "        [0.4842],\n",
            "        [0.4965],\n",
            "        [0.5024],\n",
            "        [0.4958],\n",
            "        [0.4779],\n",
            "        [0.4966],\n",
            "        [0.4911],\n",
            "        [0.4993],\n",
            "        [0.4864],\n",
            "        [0.4884],\n",
            "        [0.4911],\n",
            "        [0.4904],\n",
            "        [0.4927],\n",
            "        [0.4970],\n",
            "        [0.4941],\n",
            "        [0.4935],\n",
            "        [0.4979],\n",
            "        [0.4817],\n",
            "        [0.5008],\n",
            "        [0.4900],\n",
            "        [0.4945],\n",
            "        [0.5015],\n",
            "        [0.4883],\n",
            "        [0.4911],\n",
            "        [0.4980]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# label_dims = 2\n",
        "\n",
        "# discriminator = Discriminator()\n",
        "\n",
        "# if cuda:\n",
        "#   discriminator = discriminator.cuda()\n",
        "\n",
        "# input_img = torch.randn((32,1,256,256), device='cuda')\n",
        "# input_label = torch.randint(0,2,(32,1), device='cuda')\n",
        "\n",
        "# print(input_label.shape)\n",
        "\n",
        "# output = discriminator(input_img,input_label)\n",
        "\n",
        "# print(output.shape)\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XN6JyvR6asxR"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "adversial_loss = nn.BCELoss()\n",
        "\n",
        "if cuda:\n",
        "  generator = generator.cuda()\n",
        "  discriminator = discriminator.cuda()\n",
        "  adversial_loss = adversial_loss.cuda()\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(),lr=0.0002,betas=(0.5,0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wHvOXE2bSey_",
        "outputId": "905d5397-604f-4633-8de1-5d706749b713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch [1/1500], d_loss_real:0.014551490 , g_loss:0.000000467 , d_loss_total:0.007275978\n",
            "epoch [2/1500], d_loss_real:0.001017987 , g_loss:0.000085839 , d_loss_total:0.000551913\n",
            "epoch [3/1500], d_loss_real:5.481132507 , g_loss:0.000000012 , d_loss_total:2.740566254\n",
            "epoch [4/1500], d_loss_real:0.000203200 , g_loss:0.000000000 , d_loss_total:0.000101600\n"
          ]
        }
      ],
      "source": [
        "epochs = 1500\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  d_loss_real_print = 0\n",
        "  d_loss_total_print = 0\n",
        "  g_loss_print = 0\n",
        "  for real_images, real_labels in total_dataloader:\n",
        "\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    batch_size = real_images.shape[0]\n",
        "\n",
        "    real_targets = torch.ones((batch_size, 1), dtype=torch.float, device=device_use)\n",
        "    fake_targets = torch.zeros((batch_size, 1), dtype=torch.float, device=device_use)\n",
        "    real_labels = real_labels.to(device=device_use).unsqueeze(1)\n",
        "\n",
        "    real_images= real_images.to(device=device_use)\n",
        "\n",
        "    # optimizer_D.zero_grad()\n",
        "\n",
        "    # output_real = discriminator(real_images, real_labels)\n",
        "    # d_loss_real = adversial_loss(output_real, real_targets)\n",
        "    # d_loss_real.backward()\n",
        "    # optimizer_D.step()\n",
        "\n",
        "    # Training Generator\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    noise = torch.randn((batch_size, 510, 8,8), dtype=torch.float, device=device_use)\n",
        "    gen_labels = torch.randint(0,2,(batch_size, 1) , device=device_use)\n",
        "\n",
        "    fake_images = generator(noise, gen_labels)\n",
        "\n",
        "    output_fake = discriminator(fake_images, gen_labels)\n",
        "    g_loss = adversial_loss(output_fake, fake_targets)\n",
        "    g_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    # Training Discriminaotr\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    output_real = discriminator(real_images, real_labels)\n",
        "    d_loss_real = adversial_loss(output_real, real_targets)\n",
        "\n",
        "    output_fake = discriminator(fake_images.detach(), gen_labels)\n",
        "    d_loss_fake = adversial_loss(output_fake, fake_targets)\n",
        "\n",
        "    d_loss = (d_loss_real + d_loss_fake)/2\n",
        "    d_loss.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    d_loss_real_print = d_loss_real.item()\n",
        "    d_loss_total_print = d_loss.item()\n",
        "    g_loss_print = g_loss.item()\n",
        "\n",
        "\n",
        "  print('epoch [{}/{}], d_loss_real:{:.9f}'.format(epoch+1, epochs, d_loss_real_print),\n",
        "        ', g_loss:{:.9f}'.format(g_loss_print),\n",
        "        ', d_loss_total:{:.9f}'.format(d_loss_total_print))\n",
        "\n",
        "  if epoch%100 == 0:\n",
        "    generator.eval()\n",
        "    discriminator.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      test_size = 20\n",
        "\n",
        "      noise = torch.randn((test_size, 510, 8,8), dtype=torch.float, device=device_use)\n",
        "      gen_labels = torch.randint(0,2,(test_size, 1), device=device_use)\n",
        "\n",
        "      fake_images = generator(noise, gen_labels)\n",
        "\n",
        "      to_pil = transforms.ToPILImage()\n",
        "\n",
        "      output_dir = '/content/drive/MyDrive/Dataset_SEM_Images/Output_Images/' + f\"epoch_{epoch}_\"\n",
        "\n",
        "      os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "      for idx in range(fake_images.size(0)):\n",
        "        img = to_pil(fake_images[idx])\n",
        "        img.save(f\"{output_dir}/image_{idx}_{gen_labels[idx,0]}.png\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}